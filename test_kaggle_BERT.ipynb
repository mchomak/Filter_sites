{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website_url</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.booking.com/index.html?aid=1743217</td>\n",
       "      <td>official site good hotel accommodation big sav...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://travelsites.com/expedia/</td>\n",
       "      <td>expedia hotel book sites like use vacation wor...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://travelsites.com/tripadvisor/</td>\n",
       "      <td>tripadvisor hotel book sites like previously d...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.momondo.in/?ispredir=true</td>\n",
       "      <td>cheap flights search compare flights momondo f...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ebookers.com/?AFFCID=EBOOKERS-UK.n...</td>\n",
       "      <td>bot create free account create free account si...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         website_url  \\\n",
       "0     https://www.booking.com/index.html?aid=1743217   \n",
       "1                   https://travelsites.com/expedia/   \n",
       "2               https://travelsites.com/tripadvisor/   \n",
       "3              https://www.momondo.in/?ispredir=true   \n",
       "4  https://www.ebookers.com/?AFFCID=EBOOKERS-UK.n...   \n",
       "\n",
       "                                                text category  \n",
       "0  official site good hotel accommodation big sav...   Travel  \n",
       "1  expedia hotel book sites like use vacation wor...   Travel  \n",
       "2  tripadvisor hotel book sites like previously d...   Travel  \n",
       "3  cheap flights search compare flights momondo f...   Travel  \n",
       "4  bot create free account create free account si...   Travel  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  pd.read_csv(\"website_classification.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "<class 'str'>    1408\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö –≤ —Å—Ç–æ–ª–±—Ü–µ text\n",
    "print(df['text'].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å–ø–∏—Å–∫–æ–≤ –≤ —Å—Ç—Ä–æ–∫–∏ (–µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ)\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –∏ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫\n",
    "df = df.dropna(subset=['text', 'category'])\n",
    "df = df[df['text'].str.strip().astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ —á–∏—Å–ª–æ–≤—ã–µ –º–µ—Ç–∫–∏\n",
    "df['label'] = df['category'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PythonScripts\\Filter_sites\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –∏ –º–æ–¥–µ–ª–∏ BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "num_labels = df['label'].nunique()\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Hugging Face Datasets\n",
    "dataset = Dataset.from_pandas(df[['text', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1408/1408 [00:09<00:00, 149.05 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True)\n",
    "\n",
    "# –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "dataset = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–Ω—É–∂–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤\n",
    "dataset = dataset.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è PyTorch\n",
    "dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏\n",
    "train_testvalid = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=42)\n",
    "train_dataset = train_testvalid['train']\n",
    "eval_dataset = test_valid['train']\n",
    "test_dataset = test_valid['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PythonScripts\\Filter_sites\\.venv\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    remove_unused_columns=False,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–µ–Ω–µ—Ä–∞\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/423 [00:00<?, ?it/s]d:\\PythonScripts\\Filter_sites\\.venv\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      " 24%|‚ñà‚ñà‚ñé       | 100/423 [00:47<02:24,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3464, 'grad_norm': 7.400256633758545, 'learning_rate': 3.817966903073286e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 141/423 [01:05<01:55,  2.45it/s]d:\\PythonScripts\\Filter_sites\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "                                                 \n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 141/423 [01:07<01:55,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7035578489303589, 'eval_accuracy': 0.851063829787234, 'eval_f1': 0.838767339245441, 'eval_precision': 0.8566834558995813, 'eval_recall': 0.851063829787234, 'eval_runtime': 2.3554, 'eval_samples_per_second': 59.862, 'eval_steps_per_second': 3.821, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 200/423 [01:33<01:37,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7116, 'grad_norm': 15.36422061920166, 'learning_rate': 2.6359338061465723e-05, 'epoch': 1.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 282/423 [02:09<00:59,  2.38it/s]d:\\PythonScripts\\Filter_sites\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "                                                 \n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 282/423 [02:12<00:59,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3627060055732727, 'eval_accuracy': 0.9290780141843972, 'eval_f1': 0.9221348286462288, 'eval_precision': 0.9233987053135988, 'eval_recall': 0.9290780141843972, 'eval_runtime': 2.3191, 'eval_samples_per_second': 60.8, 'eval_steps_per_second': 3.881, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 300/423 [02:20<00:54,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3224, 'grad_norm': 11.382461547851562, 'learning_rate': 1.4539007092198581e-05, 'epoch': 2.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 400/423 [03:03<00:09,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1419, 'grad_norm': 7.976169586181641, 'learning_rate': 2.7186761229314422e-06, 'epoch': 2.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 423/423 [03:13<00:00,  2.44it/s]d:\\PythonScripts\\Filter_sites\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "                                                 \n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 423/423 [03:19<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3245522379875183, 'eval_accuracy': 0.9290780141843972, 'eval_f1': 0.9213942761106694, 'eval_precision': 0.9235276543787183, 'eval_recall': 0.9290780141843972, 'eval_runtime': 2.2184, 'eval_samples_per_second': 63.56, 'eval_steps_per_second': 4.057, 'epoch': 3.0}\n",
      "{'train_runtime': 199.5763, 'train_samples_per_second': 16.926, 'train_steps_per_second': 2.119, 'train_loss': 0.841328156473507, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=423, training_loss=0.841328156473507, metrics={'train_runtime': 199.5763, 'train_samples_per_second': 16.926, 'train_steps_per_second': 2.119, 'total_flos': 888900866113536.0, 'train_loss': 0.841328156473507, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:01<00:00,  4.57it/s]d:\\PythonScripts\\Filter_sites\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:01<00:00,  4.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3245522379875183,\n",
       " 'eval_accuracy': 0.9290780141843972,\n",
       " 'eval_f1': 0.9213942761106694,\n",
       " 'eval_precision': 0.9235276543787183,\n",
       " 'eval_recall': 0.9290780141843972,\n",
       " 'eval_runtime': 2.1114,\n",
       " 'eval_samples_per_second': 66.781,\n",
       " 'eval_steps_per_second': 4.263,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:02<00:00,  2.98it/s]d:\\PythonScripts\\Filter_sites\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:02<00:00,  3.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "labels = test_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                          Adult       1.00      1.00      1.00         3\n",
      "             Business/Corporate       1.00      0.83      0.91        12\n",
      "       Computers and Technology       0.77      1.00      0.87        10\n",
      "                     E-Commerce       1.00      1.00      1.00        12\n",
      "                      Education       0.86      1.00      0.92        12\n",
      "                           Food       1.00      1.00      1.00         7\n",
      "                         Forums       0.00      0.00      0.00         2\n",
      "                          Games       1.00      1.00      1.00         8\n",
      "             Health and Fitness       1.00      1.00      1.00         8\n",
      "             Law and Government       0.92      1.00      0.96        11\n",
      "                           News       0.80      0.73      0.76        11\n",
      "                    Photography       1.00      0.83      0.91         6\n",
      "Social Networking and Messaging       0.71      0.71      0.71         7\n",
      "                         Sports       0.90      1.00      0.95         9\n",
      "             Streaming Services       1.00      0.90      0.95        10\n",
      "                         Travel       1.00      1.00      1.00        13\n",
      "\n",
      "                       accuracy                           0.92       141\n",
      "                      macro avg       0.87      0.88      0.87       141\n",
      "                   weighted avg       0.91      0.92      0.92       141\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PythonScripts\\Filter_sites\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\PythonScripts\\Filter_sites\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\PythonScripts\\Filter_sites\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–∞—Ç–µ–≥–æ—Ä–∏–π\n",
    "df['category'] = df['category'].astype('category')\n",
    "category_names = df['category'].cat.categories.tolist()\n",
    "\n",
    "# –í—ã–≤–æ–¥ –æ—Ç—á–µ—Ç–∞ –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "print(classification_report(labels, preds, target_names=category_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
